{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input,Embedding, Dense, LSTM\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:18:46.530830Z","iopub.execute_input":"2025-06-23T06:18:46.531699Z","iopub.status.idle":"2025-06-23T06:18:46.536483Z","shell.execute_reply.started":"2025-06-23T06:18:46.531610Z","shell.execute_reply":"2025-06-23T06:18:46.535542Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Loading CSV (columns: 'source', 'target') in chunks \nchunksize = 10000\nchunks = pd.read_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv', chunksize=chunksize)   \nsource_texts, target_texts = [], []\n\nfor chunk in chunks:\n    source_texts.extend(chunk['en'].astype(str).to_list())\n    target_texts.extend(chunk['fr'].astype(str).to_list())\n\nsource_texts = source_texts[:100000]\ntarget_texts = target_texts[:100000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:18:46.538225Z","iopub.execute_input":"2025-06-23T06:18:46.538565Z","iopub.status.idle":"2025-06-23T06:20:49.051876Z","shell.execute_reply.started":"2025-06-23T06:18:46.538539Z","shell.execute_reply":"2025-06-23T06:20:49.051237Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Tokenizing\nnum_words = 10000\nsrc_tokenizer = Tokenizer(num_words=num_words, filters='', oov_token='<OOV>')\ntgt_tokenizer = Tokenizer(num_words=num_words, filters='', oov_token='<OOV>')\n\nsrc_tokenizer.fit_on_texts(source_texts)\ntgt_tokenizer.fit_on_texts(target_texts)\n\nsrc_sequences = src_tokenizer.texts_to_sequences(source_texts)\ntgt_sequences = tgt_tokenizer.texts_to_sequences(target_texts)\n\nmax_src_len = int(np.percentile([len(seq) for seq in src_sequences], 75))\nmax_tgt_len =int(np.percentile([len(seq) for seq in tgt_sequences], 75))\n\nsrc_sequences = pad_sequences(src_sequences, maxlen=max_src_len, padding='post')\ntgt_sequences = pad_sequences(tgt_sequences, maxlen=max_tgt_len, padding='post')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:49.052654Z","iopub.execute_input":"2025-06-23T06:20:49.052890Z","iopub.status.idle":"2025-06-23T06:20:57.689987Z","shell.execute_reply.started":"2025-06-23T06:20:49.052864Z","shell.execute_reply":"2025-06-23T06:20:57.689160Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"src_train, src_val, tgt_train, tgt_val = train_test_split(src_sequences, tgt_sequences, test_size=0.2, random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:57.690902Z","iopub.execute_input":"2025-06-23T06:20:57.691300Z","iopub.status.idle":"2025-06-23T06:20:57.725112Z","shell.execute_reply.started":"2025-06-23T06:20:57.691272Z","shell.execute_reply":"2025-06-23T06:20:57.724558Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"embed_dim=256\nunits=512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:57.726913Z","iopub.execute_input":"2025-06-23T06:20:57.727276Z","iopub.status.idle":"2025-06-23T06:20:57.731111Z","shell.execute_reply.started":"2025-06-23T06:20:57.727260Z","shell.execute_reply":"2025-06-23T06:20:57.730362Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"##Encoder\nenco_inputs = Input(shape=(max_src_len,))\nenc_emb = Embedding(num_words, embed_dim)(enco_inputs)\nenco_lstm, state_h, state_c = LSTM(units, return_state=True)(enc_emb)\nencoder_states=[state_h, state_c]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:57.731742Z","iopub.execute_input":"2025-06-23T06:20:57.731989Z","iopub.status.idle":"2025-06-23T06:20:57.898911Z","shell.execute_reply.started":"2025-06-23T06:20:57.731965Z","shell.execute_reply":"2025-06-23T06:20:57.898156Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"##Decoder\ndeco_inputs = Input(shape=(max_tgt_len,))\ndeco_emb = Embedding(num_words, embed_dim)(deco_inputs)\ndeco_lstm = LSTM(units, return_sequences=True, return_state=True)\ndeco_outputs, _, _ = deco_lstm(deco_emb, initial_state = encoder_states) \ndeco_dense = Dense(num_words, activation = 'softmax')\ndeco_outputs = deco_dense(deco_outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:57.899804Z","iopub.execute_input":"2025-06-23T06:20:57.900093Z","iopub.status.idle":"2025-06-23T06:20:58.069801Z","shell.execute_reply.started":"2025-06-23T06:20:57.900074Z","shell.execute_reply":"2025-06-23T06:20:58.069272Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"model = Model([enco_inputs, deco_inputs], deco_outputs)\nmodel.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:58.070761Z","iopub.execute_input":"2025-06-23T06:20:58.070985Z","iopub.status.idle":"2025-06-23T06:20:58.080500Z","shell.execute_reply.started":"2025-06-23T06:20:58.070967Z","shell.execute_reply":"2025-06-23T06:20:58.079806Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Prepare decoder target data (shifted by one)\ntgt_train_out = np.expand_dims(np.roll(tgt_train, -1, axis=1), -1)\ntgt_val_out = np.expand_dims(np.roll(tgt_val, -1, axis=1), -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:58.081291Z","iopub.execute_input":"2025-06-23T06:20:58.081946Z","iopub.status.idle":"2025-06-23T06:20:58.096208Z","shell.execute_reply.started":"2025-06-23T06:20:58.081926Z","shell.execute_reply":"2025-06-23T06:20:58.095525Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"chunk_size =10000\ntotal_size = len(src_train)\n\nfor i in range(0, total_size, chunk_size):\n    print(f\"Training on rows {i} to {i+chunk_size}...\")\n    src_chunk = src_train[i:i+chunk_size]\n    tgt_chunk = tgt_train[i:i+chunk_size]\n\n    tgt_out_chunk = np.expand_dims(np.roll(tgt_chunk, -1, axis =1), -1)\n\n    model.fit([src_chunk, tgt_chunk], tgt_out_chunk,\n              batch_size=64, epochs=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:20:58.096929Z","iopub.execute_input":"2025-06-23T06:20:58.097178Z","iopub.status.idle":"2025-06-23T06:23:56.303936Z","shell.execute_reply.started":"2025-06-23T06:20:58.097153Z","shell.execute_reply":"2025-06-23T06:23:56.303364Z"}},"outputs":[{"name":"stdout","text":"Training on rows 0 to 10000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - accuracy: 0.3537 - loss: 5.3569\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.4240 - loss: 4.0076\nTraining on rows 10000 to 20000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.4373 - loss: 3.8161\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.4521 - loss: 3.5477\nTraining on rows 20000 to 30000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - accuracy: 0.4627 - loss: 3.4618\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.4755 - loss: 3.2392\nTraining on rows 30000 to 40000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.4726 - loss: 3.2787\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.4909 - loss: 3.0412\nTraining on rows 40000 to 50000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.4877 - loss: 3.1343\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.4989 - loss: 2.9385\nTraining on rows 50000 to 60000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.5028 - loss: 2.9852\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.5086 - loss: 2.8288\nTraining on rows 60000 to 70000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.5133 - loss: 2.8768\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.5193 - loss: 2.7253\nTraining on rows 70000 to 80000...\nEpoch 1/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.5177 - loss: 2.8146\nEpoch 2/2\n\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.5317 - loss: 2.6240\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\n\ndef decode_sequence(input_seq):\n    # For simplicity, just use the model to predict one batch\n    pred = model.predict([input_seq, np.zeros((input_seq.shape[0], max_tgt_len))])\n    pred_seq = np.argmax(pred, axis=-1)\n    return pred_seq\n\n# Evaluate on a few samples\nfor i in range(5):\n    src = src_val[i:i+1]\n    tgt = tgt_val[i]\n    pred_seq = decode_sequence(src)[0]\n    tgt_words = [w for w in tgt if w != 0]\n    pred_words = [w for w in pred_seq if w != 0]\n    reference = [tgt_tokenizer.sequences_to_texts([tgt_words])[0].split()]\n    candidate = tgt_tokenizer.sequences_to_texts([pred_words])[0].split()\n    print(\"BLEU:\", sentence_bleu(reference, candidate))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:23:56.304817Z","iopub.execute_input":"2025-06-23T06:23:56.305028Z","iopub.status.idle":"2025-06-23T06:23:57.436004Z","shell.execute_reply.started":"2025-06-23T06:23:56.305011Z","shell.execute_reply":"2025-06-23T06:23:57.435413Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step\nBLEU: 4.117940420322104e-237\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\nBLEU: 5.573026331357879e-238\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\nBLEU: 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 2-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 3-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \nThe hypothesis contains 0 counts of 4-gram overlaps.\nTherefore the BLEU score evaluates to 0, independently of\nhow many N-gram overlaps of lower order it contains.\nConsider using lower n-gram order or use SmoothingFunction()\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\nBLEU: 4.634131446844473e-244\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\nBLEU: 0\n","output_type":"stream"}],"execution_count":21}]}