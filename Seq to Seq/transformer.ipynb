{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1926230,"sourceType":"datasetVersion","datasetId":1148896}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers torch sentencepiece\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T15:32:45.006419Z","iopub.execute_input":"2025-06-19T15:32:45.006609Z","iopub.status.idle":"2025-06-19T15:32:48.316925Z","shell.execute_reply.started":"2025-06-19T15:32:45.006592Z","shell.execute_reply":"2025-06-19T15:32:48.315954Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install -U transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T15:32:48.317896Z","iopub.execute_input":"2025-06-19T15:32:48.318149Z","iopub.status.idle":"2025-06-19T15:32:51.589479Z","shell.execute_reply.started":"2025-06-19T15:32:48.318122Z","shell.execute_reply":"2025-06-19T15:32:51.588483Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\ndataset = Dataset.from_csv('/kaggle/input/en-fr-translation-dataset/en-fr.csv') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:01:07.791853Z","iopub.execute_input":"2025-06-19T16:01:07.792188Z","iopub.status.idle":"2025-06-19T16:01:08.252649Z","shell.execute_reply.started":"2025-06-19T16:01:07.792165Z","shell.execute_reply":"2025-06-19T16:01:08.251866Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ff32240f034fda9180bec7654e10ff"}},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from datasets import DatasetDict\n\n# Assume dataset is already a DatasetDict with at least 'train'\nsplit = dataset.train_test_split(test_size=0.2)\n\ndataset = DatasetDict({\n    'train': split['train'],\n    'validation': split['test']\n})\n\n\ndataset['train'] = dataset['train'].select(range(min(200000, len(dataset['train']))))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:01:17.964222Z","iopub.execute_input":"2025-06-19T16:01:17.964834Z","iopub.status.idle":"2025-06-19T16:01:24.066967Z","shell.execute_reply.started":"2025-06-19T16:01:17.964812Z","shell.execute_reply":"2025-06-19T16:01:24.066351Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"dataset['validation'] = dataset['validation'].select(range(min(100000, len(dataset['validation']))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:01:25.763161Z","iopub.execute_input":"2025-06-19T16:01:25.763418Z","iopub.status.idle":"2025-06-19T16:01:26.323697Z","shell.execute_reply.started":"2025-06-19T16:01:25.763402Z","shell.execute_reply":"2025-06-19T16:01:26.323136Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"from transformers import MarianTokenizer\n\nmodel_name = 'Helsinki-NLP/opus-mt-en-fr'\ntokenizer = MarianTokenizer.from_pretrained(model_name)\n\ndef preprocess_function(examples):\n    # Ensure inputs are strings and handle any None values\n    inputs = [str(text) if text is not None else \"\" for text in examples['en']]\n    targets = [str(text) if text is not None else \"\" for text in examples['fr']]\n    \n    # Tokenize inputs\n    model_inputs = tokenizer(\n        inputs, \n        max_length=64, \n        truncation=True, \n        padding='max_length',\n        return_tensors=None  # Don't return tensors yet\n    )\n    \n    # Tokenize targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            targets, \n            max_length=64, \n            truncation=True, \n            padding='max_length',\n            return_tensors=None  # Don't return tensors yet\n        )\n    \n    # Replace padding tokens in labels with -100\n    labels[\"input_ids\"] = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label] \n        for label in labels[\"input_ids\"]\n    ]\n    \n    model_inputs['labels'] = labels['input_ids']\n    return model_inputs\n\n# Re-apply preprocessing\nprint(\"Re-processing dataset...\")\ntokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n\n# Verify the data format\nprint(\"Sample processed data:\")\nprint(tokenized_datasets['train'][0])\nprint(\"Keys:\", tokenized_datasets['train'].column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:01:30.025610Z","iopub.execute_input":"2025-06-19T16:01:30.026363Z","iopub.status.idle":"2025-06-19T16:05:05.923316Z","shell.execute_reply.started":"2025-06-19T16:01:30.026338Z","shell.execute_reply":"2025-06-19T16:05:05.922546Z"}},"outputs":[{"name":"stdout","text":"Re-processing dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f68592b8cb24222a4b3384778388bf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0efe4f2fe8e4cc0b9ae748725f24f0e"}},"metadata":{}},{"name":"stdout","text":"Sample processed data:\n{'input_ids': [97, 669, 10192, 1034, 545, 176, 33, 58, 48892, 9, 12, 57, 64, 397, 4, 227, 272, 228, 45, 264, 30, 4, 819, 7, 15926, 10, 280, 45, 881, 64, 860, 3038, 766, 0, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513, 59513], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [277, 14, 1, 426, 307, 2, 19, 1070, 3825, 221, 29, 153, 16, 14767, 89, 5162, 59, 9271, 89, 17, 8, 952, 1083, 4618, 70, 9141, 36, 19, 7773, 11, 70, 15469, 5, 454, 3038, 422, 1958, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\nKeys: ['input_ids', 'attention_mask', 'labels']\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"from transformers import MarianMTModel, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = MarianMTModel.from_pretrained(model_name)\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n\n# Optimized training arguments\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    per_device_train_batch_size=16,\n    num_train_epochs=1,\n    max_steps=30,  # Short but visible training\n    logging_steps=5,  # Log every 5 steps\n    save_strategy='no',  # Don't save to speed up\n    eval_strategy='no',  # Skip evaluation for speed\n    disable_tqdm=False,  # Keep progress bars\n    fp16=True,\n    dataloader_num_workers=0,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:10:12.940433Z","iopub.execute_input":"2025-06-19T16:10:12.940761Z","iopub.status.idle":"2025-06-19T16:10:13.694499Z","shell.execute_reply.started":"2025-06-19T16:10:12.940738Z","shell.execute_reply":"2025-06-19T16:10:13.693707Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n# Manual training with guaranteed progress display\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nmodel.train()\n\n# Create small dataloader for testing\nsmall_dataset = tokenized_datasets['train'].select(range(50))\ntrain_dataloader = DataLoader(small_dataset, batch_size=8, collate_fn=data_collator)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n\nprint(\"=== Manual Training Started ===\")\ntotal_steps = 10  # Limit steps for quick testing\n\nwith tqdm(total=total_steps, desc=\"Training\") as pbar:\n    step_count = 0\n    for epoch in range(1):\n        epoch_loss = 0\n        for batch in train_dataloader:\n            if step_count >= total_steps:\n                break\n                \n            # Move batch to device\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            # Forward pass\n            outputs = model(**batch)\n            loss = outputs.loss\n            \n            # Backward pass\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Update progress\n            step_count += 1\n            epoch_loss += loss.item()\n            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n            pbar.update(1)\n            \n            # Print every few steps\n            if step_count % 3 == 0:\n                print(f\"Step {step_count}/{total_steps} - Loss: {loss.item():.4f}\")\n\nprint(f\"=== Training Completed - Average Loss: {epoch_loss/step_count:.4f} ===\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:10:16.504685Z","iopub.execute_input":"2025-06-19T16:10:16.505223Z","iopub.status.idle":"2025-06-19T16:10:17.430591Z","shell.execute_reply.started":"2025-06-19T16:10:16.505180Z","shell.execute_reply":"2025-06-19T16:10:17.429737Z"}},"outputs":[{"name":"stdout","text":"=== Manual Training Started ===\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|████      | 4/10 [00:00<00:00,  8.78it/s, loss=1.1448]","output_type":"stream"},{"name":"stdout","text":"Step 3/10 - Loss: 2.0706\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|███████   | 7/10 [00:00<00:00,  9.00it/s, loss=0.9985]","output_type":"stream"},{"name":"stdout","text":"Step 6/10 - Loss: 0.7560\n=== Training Completed - Average Loss: 1.6201 ===\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\nchencherry = SmoothingFunction()\n\ndef compute_bleu(reference, candidate):\n    return sentence_bleu([reference], candidate, smoothing_function=chencherry.method4)\n\n# Example: Generate and evaluate\ninputs = tokenizer(\"My father's name is Jahid Ali  \", return_tensors=\"pt\", padding=True).to(model.device)\ntranslated = model.generate(**inputs)\noutput = tokenizer.decode(translated[0], skip_special_tokens=True)\nreference = \"Mon père s'appelle Jahid Ali.\".split()\ncandidate = output.split()\nbleu = compute_bleu(reference, candidate)\nprint(\"BLEU Score:\", bleu)\nprint(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-19T16:16:33.776780Z","iopub.execute_input":"2025-06-19T16:16:33.777149Z","iopub.status.idle":"2025-06-19T16:16:33.913072Z","shell.execute_reply.started":"2025-06-19T16:16:33.777123Z","shell.execute_reply":"2025-06-19T16:16:33.912256Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 1.0\nMon père s'appelle Jahid Ali.\n","output_type":"stream"}],"execution_count":61}]}