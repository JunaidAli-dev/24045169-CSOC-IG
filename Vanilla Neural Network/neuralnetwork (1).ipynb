{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3538,"sourceType":"datasetVersion","datasetId":792}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:56:59.615006Z","iopub.execute_input":"2025-05-29T05:56:59.615352Z","iopub.status.idle":"2025-05-29T05:56:59.965086Z","shell.execute_reply.started":"2025-05-29T05:56:59.615328Z","shell.execute_reply":"2025-05-29T05:56:59.964165Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/noshowappointments/KaggleV2-May-2016.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, f1_score, precision_recall_curve, average_precision_score, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:56:59.966616Z","iopub.execute_input":"2025-05-29T05:56:59.967112Z","iopub.status.idle":"2025-05-29T05:57:00.707164Z","shell.execute_reply.started":"2025-05-29T05:56:59.967075Z","shell.execute_reply":"2025-05-29T05:57:00.706166Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/noshowappointments/KaggleV2-May-2016.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:00.708524Z","iopub.execute_input":"2025-05-29T05:57:00.709016Z","iopub.status.idle":"2025-05-29T05:57:01.152478Z","shell.execute_reply.started":"2025-05-29T05:57:00.708984Z","shell.execute_reply":"2025-05-29T05:57:01.151442Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df['No-show'] = (df['No-show'] == 'Yes').astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.154695Z","iopub.execute_input":"2025-05-29T05:57:01.154983Z","iopub.status.idle":"2025-05-29T05:57:01.175531Z","shell.execute_reply.started":"2025-05-29T05:57:01.154960Z","shell.execute_reply":"2025-05-29T05:57:01.174727Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = df.drop(['PatientId', 'AppointmentID'], axis =1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.176564Z","iopub.execute_input":"2025-05-29T05:57:01.176863Z","iopub.status.idle":"2025-05-29T05:57:01.208810Z","shell.execute_reply.started":"2025-05-29T05:57:01.176838Z","shell.execute_reply":"2025-05-29T05:57:01.207903Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\ndf['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.209767Z","iopub.execute_input":"2025-05-29T05:57:01.210112Z","iopub.status.idle":"2025-05-29T05:57:01.361444Z","shell.execute_reply.started":"2025-05-29T05:57:01.210074Z","shell.execute_reply":"2025-05-29T05:57:01.360540Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df['DaysWaiting'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.362521Z","iopub.execute_input":"2025-05-29T05:57:01.362893Z","iopub.status.idle":"2025-05-29T05:57:01.373334Z","shell.execute_reply.started":"2025-05-29T05:57:01.362864Z","shell.execute_reply":"2025-05-29T05:57:01.372351Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df = df.drop(['ScheduledDay', 'AppointmentDay'], axis = 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.374358Z","iopub.execute_input":"2025-05-29T05:57:01.374685Z","iopub.status.idle":"2025-05-29T05:57:01.399323Z","shell.execute_reply.started":"2025-05-29T05:57:01.374657Z","shell.execute_reply":"2025-05-29T05:57:01.398401Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df['DaysWaiting'] = df['DaysWaiting'].apply(lambda x: x if x>=0 else 0)\ndf['Age'] = df['Age'].clip(lower=0, upper=100)\ndf['Gender'] = df['Gender'].map({'F':0, 'M':1})\n\ndf = pd.get_dummies(df, columns=['Neighbourhood'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.400628Z","iopub.execute_input":"2025-05-29T05:57:01.400933Z","iopub.status.idle":"2025-05-29T05:57:01.503741Z","shell.execute_reply.started":"2025-05-29T05:57:01.400907Z","shell.execute_reply":"2025-05-29T05:57:01.502801Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#Normalizing numerical data\nnumerical_cols = ['Age', 'DaysWaiting', 'Scholarship', 'Hipertension', 'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received']\nfor col in numerical_cols:\n    df[col] = (df[col] - df[col].mean())/df[col].std()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.506482Z","iopub.execute_input":"2025-05-29T05:57:01.506791Z","iopub.status.idle":"2025-05-29T05:57:01.531706Z","shell.execute_reply.started":"2025-05-29T05:57:01.506767Z","shell.execute_reply":"2025-05-29T05:57:01.530762Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"X = df.drop('No-show', axis =1).values\ny= df['No-show'].values.reshape(-1,1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.532642Z","iopub.execute_input":"2025-05-29T05:57:01.532883Z","iopub.status.idle":"2025-05-29T05:57:01.835000Z","shell.execute_reply.started":"2025-05-29T05:57:01.532865Z","shell.execute_reply":"2025-05-29T05:57:01.834065Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:01.835929Z","iopub.execute_input":"2025-05-29T05:57:01.836298Z","iopub.status.idle":"2025-05-29T05:57:03.285628Z","shell.execute_reply.started":"2025-05-29T05:57:01.836268Z","shell.execute_reply":"2025-05-29T05:57:03.284619Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Neural-Network Class\nclass NeuralNetwork:\n    def __init__(self, input_size, hidden_size,output_size):\n        #He initialization\n        self.W1 = np.random.randn(input_size, hidden_size).astype(np.float64) * np.sqrt(2 / input_size)\n        self.b1 = np.zeros((1, hidden_size), dtype=np.float64)\n        self.W2 = np.random.randn(hidden_size, output_size).astype(np.float64) * np.sqrt(2 / hidden_size)\n        self.b2 = np.zeros((1, output_size), dtype=np.float64)\n\n    def relu(self, Z):\n        return np.maximum(0, Z)\n\n    def sigmoid(Z):\n        return 1 / (1 +np.exp(-Z))\n\n    def forward(self, X):\n        self.Z1 = np.dot(X, self.W1) + self.b1\n        self.A1 = self.relu(self.Z1)\n        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n        self.A2 = self.relu(self.Z2)\n        return self.A2\n\n    def compute_loss(self, y, y_pred):\n        epsilon = 1e-8  # Avoid log(0)\n        y = np.array(y, dtype=float).reshape(-1)\n        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n        y_pred = np.array(y_pred, dtype=float).reshape(-1)\n        loss = -np.mean(y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n        return loss\n\n\n\n    def backward(self, X, y, y_pred, learning_rate):\n        m = y.shape[0] # Numbers of sample\n        dZ2 = y_pred -y\n        dW2 = np.dot(self.A1.T, dZ2) / m\n        db2 = np.sum(dZ2, axis = 0, keepdims = True)/m\n\n        dZ1 = np.dot(dZ2, self.W2.T) * (self.Z1>0)\n        dW1 = np.dot(X.T, dZ1)/ m\n        db1 = np.sum(dZ1, axis=0, keepdims =True)/m\n\n        #update parameters\n        self.W2 = self.W2 - learning_rate * dW2\n        self.b2 = self.b2 - learning_rate * db2\n        self.W1 = self.W1 - learning_rate * dW1\n        self.b1 = self.b1 - learning_rate * db1\n\n    def train(self, X, y, epochs, learning_rate):\n        for epoch in range(epochs):\n            y_pred = self.forward(X)\n            loss = self.compute_loss(y, y_pred)\n            self.backward(X, y, y_pred, learning_rate)\n            if epoch%100 ==0:\n                print(f'Epoch{epoch} Loss: {loss:.4f}')\n\n\n    def predict(self, X):\n        return (self.forward(X) >= 0.5).astype(int)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:57:03.286644Z","iopub.execute_input":"2025-05-29T05:57:03.286978Z","iopub.status.idle":"2025-05-29T05:57:03.299892Z","shell.execute_reply.started":"2025-05-29T05:57:03.286949Z","shell.execute_reply":"2025-05-29T05:57:03.298771Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"input_size = X_train.shape[1]\nhidden_size =10\noutput_size =1 \n\nmodel = NeuralNetwork(input_size, hidden_size, output_size)\nmodel.train(X_train[:2000], y_train[:2000], epochs=1000, learning_rate=0.01)\n\ntrain_pred = model.predict(X_train)\ntest_pred = model.predict(X_test)\n\nprint(\"\\nTraining Metrics:\")\nprint(f\"Training Accuracy: {np.mean(train_pred == y_train):.4f}\")\nprint(f\"Training F1: {f1_score(y_train, train_pred):.4f}\")\nprint(f\"PR-AUC: {average_precision_score(y_train, train_pred):.4f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_train, train_pred))\n\nprint(\"\\nTest Metrics:\")\nprint(f\"Test Accuracy: {np.mean(test_pred == y_test):.4f}\")\nprint(f\"Test F1: {f1_score(y_test, test_pred):.4f}\")\nprint(f\"PR-AUC: {average_precision_score(y_test, test_pred):.4f}\")\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, test_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T05:59:05.267189Z","iopub.execute_input":"2025-05-29T05:59:05.267563Z","iopub.status.idle":"2025-05-29T06:01:40.478196Z","shell.execute_reply.started":"2025-05-29T05:59:05.267536Z","shell.execute_reply":"2025-05-29T06:01:40.477281Z"}},"outputs":[{"name":"stdout","text":"Epoch0 Loss: 2.7168\nEpoch100 Loss: 1.8236\nEpoch200 Loss: 1.1902\nEpoch300 Loss: 1.0016\nEpoch400 Loss: 0.9381\nEpoch500 Loss: 0.8970\nEpoch600 Loss: 0.8629\nEpoch700 Loss: 0.8139\nEpoch800 Loss: 0.7740\nEpoch900 Loss: 0.7467\n\nTraining Metrics:\nTraining Accuracy: 0.7858\nTraining F1: 0.1016\nPR-AUC: 0.2102\nConfusion Matrix:\n [[68408  2131]\n [16811  1071]]\n\nTest Metrics:\nTest Accuracy: 0.7862\nTest F1: 0.1035\nPR-AUC: 0.2085\nConfusion Matrix:\n [[17106   563]\n [ 4164   273]]\n","output_type":"stream"}],"execution_count":18}]}
